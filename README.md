# âš™ï¸ DAGRunner - Lightweight Local DAG Execution Tool

**DAGRunner** is a simple, standalone command-line tool for executing Directed Acyclic Graph (DAG)-based pipelines defined in a JSON file. It supports shell commands, Python scripts, and Python function calls using the interpreter found in your project environment.

---

## âœ¨ Features

- âœ… Local execution only â€“ no cloud or orchestration platform dependencies
- ğŸ§© Define DAGs in `dagrunner.json`
- ğŸ›  Task types: `shell`, `script`, `function`
- ğŸ“œ Full stdout/stderr logging
- ğŸ§µ Sequential tasks within jobs, parallel execution of jobs
- ğŸ Automatically resolves the appropriate Python interpreter
- ğŸ” Dry-run mode for previewing execution plans
- ğŸ“ Logs stored with timestamps per run
- ğŸ“¦ PyInstaller compatible for standalone CLI tool

---

## ğŸ“¦ Installation

To build the standalone executable:

```bash
pip install pyinstaller
pyinstaller --onefile dagrunner.py
```

Run it with:

```bash
./dist/dagrunner run
```

Or add it globally to your PATH for convenience.

---

## ğŸš€ CLI Usage

ğŸ†• Initialize a Project

```bash
dagrunner init
```

Creates a sample dagrunner.json in the current directory.

â–¶ï¸ Run DAGs

```bash
dagrunner run
```

Executes all jobs in parallel, with sequential tasks within each job.


ğŸ§ª Dry Run

```bash
dagrunner run --dry-run
```

Shows execution plan, including interpreter resolution, task order, and typesâ€”without running anything.

âœ… Validate Config

```bash
dagrunner validate
```

Checks the integrity and structure of your dagrunner.json.

ğŸ“‹ List Jobs and Tasks

```bash
dagrunner list
```

Prints all job IDs and their tasks with type annotations.

ğŸ§¬ Example dagrunner.json

```json
{
  "jobs": {
    "example_job": {
      "id": "example_job",
      "tasks": [
        {
          "id": "task1",
          "type": "shell",
          "command": "echo 'Hello World'"
        },
        {
          "id": "task2",
          "type": "script",
          "path": "scripts/example.py",
          "depends_on": ["task1"]
        },
        {
          "id": "task3",
          "type": "function",
          "path": "my_module.entry.main",
          "depends_on": ["task2"]
        }
      ]
    }
  }
}
```

---

## ğŸ§  Task Types

- ğŸ–¥ shell: Executes a shell command

- ğŸ“œ script: Runs a Python script using the resolved interpreter

- ğŸ”§ function: Executes a Python function from an importable module

---

## ğŸ§­ Interpreter Resolution

The interpreter is selected in this priority:

1. "interpreter" field in dagrunner.json (if present)

2. First python or python.exe found in the project directory

3. Python path from .code-workspace config (if available)

4. Fallback to global interpreter (sys.executable)

---

## ğŸ“‚ Logging

Each run generates a file like:

```bash
dagrunner_2025-07-27T22-02-14_example_job.log
```

Log contents include:

- ğŸ· Task ID

- ğŸŸ¢ Status (done, failed)

- â± Duration

- ğŸ“¤ STDOUT

- ğŸ“¥ STDERR

- ğŸ” Return value (for function tasks)


---


## âœ… Best Practices

- Keep dagrunner.json under version control (e.g., Git)

- Organize scripts and functions as you see fit-

- Ensure import paths are resolvable relative to project root

- Use clear task IDs and define depends_on to enforce execution order

---

## âš ï¸ Limitations

- ğŸš« No distributed/cloud execution

- âŒ No retries, retries-on-failures, or scheduling

- ğŸ–¼ No DAG visualization

---

## ğŸªª License
MIT